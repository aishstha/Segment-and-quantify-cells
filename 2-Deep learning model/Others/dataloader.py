# -*- coding: utf-8 -*-
"""Dataloader.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pxY9nFM393IP-W46vO0aeBX0TX2Iv1No
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow==2.8.1

import tensorflow as tf
print(tf.__version__)

import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

import cv2
import glob
import random
import numpy as np
from PIL import Image
from keras.utils.np_utils import normalize
import tensorflow as tf
import segmentation_models as sm
import albumentations as A

# to resolve AttributeError: module 'keras.utils' has no attribute 'get_file' using segmentation_models error
sm.set_framework('tf.keras')
sm.framework()

# Commented out IPython magic to ensure Python compatibility.
import keras
import matplotlib.pyplot as plt
# %matplotlib inline
import tensorflow as tf
from logging import LogRecord
from sklearn.model_selection import KFold
import numpy as np
from tensorflow.keras.optimizers import Adam
# from model_binary import CNetSeg
from sklearn.model_selection import train_test_split
import albumentations as A
from tensorflow.keras.utils import Sequence
import tensorflow.keras.backend as K
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
import shutil
import pandas as pd
from datetime import datetime

class Dataset:

    CLASSES = ['background', 'cell']

    def __init__(
            self,
            images_dir,
            masks_dir,
            classes=None,
            augmentation=None,
            preprocessing=None,
    ):
        self.images_fps = images_dir
        self.masks_fps = masks_dir

        # convert str names to class values on masks
        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]

        self.augmentation = augmentation
        self.preprocessing = preprocessing

    def __getitem__(self, i):

        # read data
        image = cv2.imread(self.images_fps[i])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        # image = np.expand_dims(image, axis = -1)
        mask = cv2.imread(self.masks_fps[i], 0)

        # extract certain classes from mask (e.g. cars)
        masks = [(mask == v) for v in self.class_values]
        mask = np.stack(masks, axis=-1).astype('float')

        # add background if mask is not binary
        if mask.shape[-1] != 1:
            background = 1 - mask.sum(axis=-1, keepdims=True)
            mask = np.concatenate((mask, background), axis=-1)

        # apply augmentations
        if self.augmentation:
            sample = self.augmentation(image=image, mask=mask)
            image, mask = sample['image'], sample['mask']

        # apply preprocessing
        if self.preprocessing:
            sample = self.preprocessing(image=image, mask=mask)
            image, mask = sample['image'], sample['mask']

        return image, mask

    def __len__(self):
        return len(self.images_fps)

class Dataloder(Sequence):

    def __init__(self, dataset, batch_size=1, shuffle=False):
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indexes = np.arange(len(dataset))

        self.on_epoch_end()

    def __getitem__(self, i):

        # collect batch data
        start = i * self.batch_size
        stop = (i + 1) * self.batch_size
        data = []
        for j in range(start, stop):
            data.append(self.dataset[j])

        # transpose list of lists
        batch = [np.stack(samples, axis=0) for samples in zip(*data)]

        return batch

    def __len__(self):
        """Denotes the number of batches per epoch"""
        return len(self.indexes) // self.batch_size

    def on_epoch_end(self):
        """Callback function to shuffle indexes each epoch"""
        if self.shuffle:
            self.indexes = np.random.permutation(self.indexes)

dataset = Dataset(train_image_files, train_label_files, classes=['cell'])
image, mask = dataset[5]

print(image.shape, mask.shape)